{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral\n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral\n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral\n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral\n",
       "4                minyak jarak castor oil <number> ml  neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/train.csv\")\n",
    "# clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_train_full.csv\")\n",
    "clean_train_comments['content'] = clean_train_comments['content'].apply(preprocess)\n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[gerindra, alihkan, rekomendasi, ke, agus, an,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[cuci, tangan, pakai, sunlight, stelah, itu, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[kasus, toko, obat, digerebek, fpi, propam, ak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[menkeu, melemah, nya, rupiah, lebih, berpenga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[minyak, jarak, castor, oil, number, ml]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity  \\\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral   \n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral   \n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral   \n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral   \n",
       "4                minyak jarak castor oil <number> ml  neutral   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [gerindra, alihkan, rekomendasi, ke, agus, an,...          1  \n",
       "1  [cuci, tangan, pakai, sunlight, stelah, itu, p...          1  \n",
       "2  [kasus, toko, obat, digerebek, fpi, propam, ak...          1  \n",
       "3  [menkeu, melemah, nya, rupiah, lebih, berpenga...          1  \n",
       "4           [minyak, jarak, castor, oil, number, ml]          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "clean_train_comments['content'] = clean_train_comments['content'].astype('str') \n",
    "clean_train_comments.dtypes\n",
    "clean_train_comments['tokens'] = clean_train_comments['content'].apply(tokenizer.tokenize)\n",
    "clean_train_comments['sentiment'] = clean_train_comments['polarity'].astype('category').cat.codes\n",
    "   \n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative\n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative\n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative\n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative\n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/test.csv\")\n",
    "# clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_testing_full.csv\")\n",
    "clean_test_comments['content'] = clean_test_comments['content'].apply(preprocess)\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kemarin, gue, datang, ke, tempat, makan, baru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kayak, nya, sih, gue, tidak, akan, mau, balik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kalau, dipikirpikir, sebenarnya, tidak, ada, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ini, pertama, kalinya, gua, ke, bank, buat, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[waktu, sampai, dengan, gue, pernah, disuruh, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity  \\\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative   \n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative   \n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative   \n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative   \n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [kemarin, gue, datang, ke, tempat, makan, baru...          0  \n",
       "1  [kayak, nya, sih, gue, tidak, akan, mau, balik...          0  \n",
       "2  [kalau, dipikirpikir, sebenarnya, tidak, ada, ...          0  \n",
       "3  [ini, pertama, kalinya, gua, ke, bank, buat, n...          0  \n",
       "4  [waktu, sampai, dengan, gue, pernah, disuruh, ...          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments['content'] = clean_test_comments['content'].astype('str') \n",
    "clean_test_comments.dtypes\n",
    "clean_test_comments[\"tokens\"] = clean_test_comments[\"content\"].apply(tokenizer.tokenize)\n",
    "clean_test_comments['sentiment'] = clean_test_comments['polarity'].astype('category').cat.codes\n",
    "\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = clean_train_comments['content']\n",
    "x_validation = clean_test_comments['content']\n",
    "y_train = clean_train_comments['sentiment']\n",
    "y_validation = clean_test_comments['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_text(text,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(text.index, text):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "x_train = labelize_text(x_train, 'TRAIN')\n",
    "x_validation = labelize_text(x_validation, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 85\n",
    "data_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load('./prosa-w2v/prosa.vec')\n",
    "# word2vec = Word2Vec.load(\"./vectorizer/tripadvisor/word2vec_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_Word_Vector(tokens, size):\n",
    "    vec = np.zeros((MAX_SEQUENCE_LENGTH - len(tokens), size))\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec = np.append(vec, word2vec[word])\n",
    "        except KeyError: \n",
    "            vec = np.append(vec, np.zeros((1, size)))\n",
    "            continue\n",
    "    vec.reshape(MAX_SEQUENCE_LENGTH, size)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "935it [00:01, 642.55it/s]\n",
      "100it [00:00, 812.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vecs = np.concatenate([[build_Word_Vector(z, 500)] for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "val_vecs = np.concatenate([[build_Word_Vector(z, 500)] for z in tqdm(map(lambda x: x.words, x_validation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "hidden_size = 10\n",
    "timesteps = MAX_SEQUENCE_LENGTH\n",
    "num_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = len(train_vecs)\n",
    "num_data_val = len(val_vecs)\n",
    "\n",
    "train_vecs = train_vecs.reshape((num_data, timesteps, data_dim))\n",
    "y_train = y_train.reshape((num_data, num_class))\n",
    "val_vecs = val_vecs.reshape((num_data_val, timesteps, data_dim))\n",
    "y_validation = y_validation.reshape((num_data_val, num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 935 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "935/935 [==============================] - ETA: 1:27 - loss: 1.1618 - acc: 0.187 - ETA: 45s - loss: 1.0995 - acc: 0.359 - ETA: 30s - loss: 1.1172 - acc: 0.32 - ETA: 23s - loss: 1.1083 - acc: 0.34 - ETA: 18s - loss: 1.1127 - acc: 0.31 - ETA: 15s - loss: 1.1167 - acc: 0.31 - ETA: 13s - loss: 1.1110 - acc: 0.34 - ETA: 11s - loss: 1.1095 - acc: 0.35 - ETA: 10s - loss: 1.1025 - acc: 0.36 - ETA: 9s - loss: 1.0984 - acc: 0.3812 - ETA: 8s - loss: 1.0987 - acc: 0.380 - ETA: 7s - loss: 1.0962 - acc: 0.385 - ETA: 6s - loss: 1.0894 - acc: 0.394 - ETA: 6s - loss: 1.0802 - acc: 0.408 - ETA: 5s - loss: 1.0754 - acc: 0.416 - ETA: 4s - loss: 1.0714 - acc: 0.414 - ETA: 4s - loss: 1.0690 - acc: 0.408 - ETA: 3s - loss: 1.0653 - acc: 0.411 - ETA: 3s - loss: 1.0642 - acc: 0.412 - ETA: 3s - loss: 1.0645 - acc: 0.410 - ETA: 2s - loss: 1.0609 - acc: 0.418 - ETA: 2s - loss: 1.0565 - acc: 0.427 - ETA: 1s - loss: 1.0542 - acc: 0.432 - ETA: 1s - loss: 1.0501 - acc: 0.434 - ETA: 1s - loss: 1.0478 - acc: 0.438 - ETA: 0s - loss: 1.0454 - acc: 0.442 - ETA: 0s - loss: 1.0418 - acc: 0.443 - ETA: 0s - loss: 1.0415 - acc: 0.443 - ETA: 0s - loss: 1.0401 - acc: 0.444 - 9s 10ms/step - loss: 1.0384 - acc: 0.4449 - val_loss: 1.0240 - val_acc: 0.4500\n",
      "Epoch 2/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.9792 - acc: 0.468 - ETA: 4s - loss: 0.9845 - acc: 0.500 - ETA: 4s - loss: 0.9850 - acc: 0.500 - ETA: 4s - loss: 0.9832 - acc: 0.500 - ETA: 4s - loss: 0.9704 - acc: 0.493 - ETA: 4s - loss: 0.9771 - acc: 0.489 - ETA: 3s - loss: 0.9702 - acc: 0.504 - ETA: 3s - loss: 0.9627 - acc: 0.511 - ETA: 3s - loss: 0.9543 - acc: 0.531 - ETA: 3s - loss: 0.9511 - acc: 0.531 - ETA: 3s - loss: 0.9471 - acc: 0.536 - ETA: 3s - loss: 0.9385 - acc: 0.554 - ETA: 2s - loss: 0.9452 - acc: 0.548 - ETA: 2s - loss: 0.9386 - acc: 0.569 - ETA: 2s - loss: 0.9364 - acc: 0.579 - ETA: 2s - loss: 0.9324 - acc: 0.584 - ETA: 2s - loss: 0.9315 - acc: 0.582 - ETA: 2s - loss: 0.9237 - acc: 0.595 - ETA: 1s - loss: 0.9176 - acc: 0.600 - ETA: 1s - loss: 0.9184 - acc: 0.598 - ETA: 1s - loss: 0.9152 - acc: 0.602 - ETA: 1s - loss: 0.9138 - acc: 0.602 - ETA: 1s - loss: 0.9144 - acc: 0.599 - ETA: 0s - loss: 0.9094 - acc: 0.604 - ETA: 0s - loss: 0.9103 - acc: 0.606 - ETA: 0s - loss: 0.9047 - acc: 0.608 - ETA: 0s - loss: 0.9048 - acc: 0.608 - ETA: 0s - loss: 0.9049 - acc: 0.606 - ETA: 0s - loss: 0.9025 - acc: 0.606 - 6s 6ms/step - loss: 0.9011 - acc: 0.6075 - val_loss: 0.9757 - val_acc: 0.5100\n",
      "Epoch 3/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.8356 - acc: 0.687 - ETA: 4s - loss: 0.8230 - acc: 0.671 - ETA: 4s - loss: 0.8387 - acc: 0.614 - ETA: 4s - loss: 0.8154 - acc: 0.664 - ETA: 4s - loss: 0.8066 - acc: 0.675 - ETA: 4s - loss: 0.8194 - acc: 0.661 - ETA: 4s - loss: 0.8009 - acc: 0.683 - ETA: 3s - loss: 0.7932 - acc: 0.691 - ETA: 3s - loss: 0.8086 - acc: 0.677 - ETA: 3s - loss: 0.8124 - acc: 0.671 - ETA: 3s - loss: 0.8077 - acc: 0.676 - ETA: 3s - loss: 0.8044 - acc: 0.684 - ETA: 2s - loss: 0.8008 - acc: 0.694 - ETA: 2s - loss: 0.8011 - acc: 0.698 - ETA: 2s - loss: 0.8003 - acc: 0.695 - ETA: 2s - loss: 0.7960 - acc: 0.697 - ETA: 2s - loss: 0.7933 - acc: 0.694 - ETA: 2s - loss: 0.7911 - acc: 0.697 - ETA: 1s - loss: 0.7898 - acc: 0.697 - ETA: 1s - loss: 0.7874 - acc: 0.696 - ETA: 1s - loss: 0.7834 - acc: 0.697 - ETA: 1s - loss: 0.7819 - acc: 0.697 - ETA: 1s - loss: 0.7821 - acc: 0.697 - ETA: 0s - loss: 0.7782 - acc: 0.697 - ETA: 0s - loss: 0.7791 - acc: 0.695 - ETA: 0s - loss: 0.7750 - acc: 0.695 - ETA: 0s - loss: 0.7759 - acc: 0.694 - ETA: 0s - loss: 0.7791 - acc: 0.694 - ETA: 0s - loss: 0.7731 - acc: 0.701 - 6s 6ms/step - loss: 0.7716 - acc: 0.7027 - val_loss: 0.9759 - val_acc: 0.5100\n",
      "Epoch 4/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.7028 - acc: 0.812 - ETA: 4s - loss: 0.7522 - acc: 0.765 - ETA: 4s - loss: 0.7147 - acc: 0.791 - ETA: 4s - loss: 0.7118 - acc: 0.765 - ETA: 4s - loss: 0.7153 - acc: 0.750 - ETA: 4s - loss: 0.7145 - acc: 0.760 - ETA: 3s - loss: 0.7036 - acc: 0.758 - ETA: 3s - loss: 0.6987 - acc: 0.753 - ETA: 3s - loss: 0.6926 - acc: 0.753 - ETA: 3s - loss: 0.6973 - acc: 0.759 - ETA: 3s - loss: 0.6943 - acc: 0.758 - ETA: 3s - loss: 0.6892 - acc: 0.763 - ETA: 2s - loss: 0.6781 - acc: 0.774 - ETA: 2s - loss: 0.6727 - acc: 0.772 - ETA: 2s - loss: 0.6719 - acc: 0.772 - ETA: 2s - loss: 0.6724 - acc: 0.773 - ETA: 2s - loss: 0.6769 - acc: 0.770 - ETA: 1s - loss: 0.6720 - acc: 0.777 - ETA: 1s - loss: 0.6748 - acc: 0.771 - ETA: 1s - loss: 0.6681 - acc: 0.773 - ETA: 1s - loss: 0.6675 - acc: 0.770 - ETA: 1s - loss: 0.6707 - acc: 0.768 - ETA: 1s - loss: 0.6683 - acc: 0.769 - ETA: 0s - loss: 0.6664 - acc: 0.769 - ETA: 0s - loss: 0.6662 - acc: 0.767 - ETA: 0s - loss: 0.6615 - acc: 0.771 - ETA: 0s - loss: 0.6658 - acc: 0.768 - ETA: 0s - loss: 0.6627 - acc: 0.769 - ETA: 0s - loss: 0.6658 - acc: 0.765 - 6s 6ms/step - loss: 0.6647 - acc: 0.7658 - val_loss: 1.0083 - val_acc: 0.5100\n",
      "Epoch 5/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.7016 - acc: 0.750 - ETA: 4s - loss: 0.5432 - acc: 0.843 - ETA: 4s - loss: 0.5944 - acc: 0.822 - ETA: 4s - loss: 0.5917 - acc: 0.796 - ETA: 4s - loss: 0.5991 - acc: 0.787 - ETA: 4s - loss: 0.5826 - acc: 0.802 - ETA: 3s - loss: 0.5845 - acc: 0.790 - ETA: 3s - loss: 0.5740 - acc: 0.789 - ETA: 3s - loss: 0.5842 - acc: 0.781 - ETA: 3s - loss: 0.5814 - acc: 0.787 - ETA: 3s - loss: 0.5872 - acc: 0.784 - ETA: 3s - loss: 0.5976 - acc: 0.781 - ETA: 2s - loss: 0.5925 - acc: 0.786 - ETA: 2s - loss: 0.5809 - acc: 0.792 - ETA: 2s - loss: 0.5824 - acc: 0.787 - ETA: 2s - loss: 0.5791 - acc: 0.789 - ETA: 2s - loss: 0.5826 - acc: 0.788 - ETA: 2s - loss: 0.5772 - acc: 0.791 - ETA: 1s - loss: 0.5819 - acc: 0.787 - ETA: 1s - loss: 0.5810 - acc: 0.787 - ETA: 1s - loss: 0.5730 - acc: 0.788 - ETA: 1s - loss: 0.5740 - acc: 0.791 - ETA: 1s - loss: 0.5788 - acc: 0.789 - ETA: 0s - loss: 0.5737 - acc: 0.791 - ETA: 0s - loss: 0.5720 - acc: 0.792 - ETA: 0s - loss: 0.5730 - acc: 0.793 - ETA: 0s - loss: 0.5679 - acc: 0.796 - ETA: 0s - loss: 0.5689 - acc: 0.795 - ETA: 0s - loss: 0.5637 - acc: 0.798 - 6s 6ms/step - loss: 0.5631 - acc: 0.7989 - val_loss: 1.0682 - val_acc: 0.4700\n",
      "Epoch 6/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.3845 - acc: 0.968 - ETA: 4s - loss: 0.4352 - acc: 0.921 - ETA: 4s - loss: 0.4963 - acc: 0.864 - ETA: 4s - loss: 0.4641 - acc: 0.875 - ETA: 4s - loss: 0.4650 - acc: 0.862 - ETA: 4s - loss: 0.4441 - acc: 0.864 - ETA: 3s - loss: 0.4310 - acc: 0.866 - ETA: 3s - loss: 0.4434 - acc: 0.855 - ETA: 3s - loss: 0.4567 - acc: 0.840 - ETA: 3s - loss: 0.4575 - acc: 0.846 - ETA: 3s - loss: 0.4595 - acc: 0.843 - ETA: 2s - loss: 0.4547 - acc: 0.849 - ETA: 2s - loss: 0.4491 - acc: 0.855 - ETA: 2s - loss: 0.4485 - acc: 0.854 - ETA: 2s - loss: 0.4595 - acc: 0.841 - ETA: 2s - loss: 0.4589 - acc: 0.837 - ETA: 2s - loss: 0.4623 - acc: 0.834 - ETA: 1s - loss: 0.4681 - acc: 0.829 - ETA: 1s - loss: 0.4633 - acc: 0.832 - ETA: 1s - loss: 0.4664 - acc: 0.834 - ETA: 1s - loss: 0.4678 - acc: 0.834 - ETA: 1s - loss: 0.4659 - acc: 0.836 - ETA: 1s - loss: 0.4643 - acc: 0.837 - ETA: 0s - loss: 0.4639 - acc: 0.837 - ETA: 0s - loss: 0.4656 - acc: 0.835 - ETA: 0s - loss: 0.4636 - acc: 0.835 - ETA: 0s - loss: 0.4675 - acc: 0.833 - ETA: 0s - loss: 0.4643 - acc: 0.834 - ETA: 0s - loss: 0.4635 - acc: 0.836 - 5s 6ms/step - loss: 0.4615 - acc: 0.8374 - val_loss: 1.1560 - val_acc: 0.4700\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - ETA: 4s - loss: 0.4590 - acc: 0.781 - ETA: 4s - loss: 0.4796 - acc: 0.828 - ETA: 4s - loss: 0.4510 - acc: 0.833 - ETA: 4s - loss: 0.4218 - acc: 0.859 - ETA: 4s - loss: 0.4039 - acc: 0.868 - ETA: 3s - loss: 0.4124 - acc: 0.859 - ETA: 3s - loss: 0.4167 - acc: 0.866 - ETA: 3s - loss: 0.4205 - acc: 0.859 - ETA: 3s - loss: 0.4100 - acc: 0.861 - ETA: 3s - loss: 0.4199 - acc: 0.856 - ETA: 3s - loss: 0.4275 - acc: 0.858 - ETA: 2s - loss: 0.4214 - acc: 0.859 - ETA: 2s - loss: 0.4174 - acc: 0.858 - ETA: 2s - loss: 0.4204 - acc: 0.857 - ETA: 2s - loss: 0.4119 - acc: 0.862 - ETA: 2s - loss: 0.4068 - acc: 0.865 - ETA: 2s - loss: 0.4048 - acc: 0.864 - ETA: 1s - loss: 0.4052 - acc: 0.866 - ETA: 1s - loss: 0.4008 - acc: 0.868 - ETA: 1s - loss: 0.4064 - acc: 0.864 - ETA: 1s - loss: 0.4007 - acc: 0.867 - ETA: 1s - loss: 0.4058 - acc: 0.867 - ETA: 1s - loss: 0.4035 - acc: 0.869 - ETA: 0s - loss: 0.4116 - acc: 0.867 - ETA: 0s - loss: 0.4090 - acc: 0.868 - ETA: 0s - loss: 0.4091 - acc: 0.867 - ETA: 0s - loss: 0.4113 - acc: 0.863 - ETA: 0s - loss: 0.4140 - acc: 0.858 - ETA: 0s - loss: 0.4180 - acc: 0.858 - 6s 6ms/step - loss: 0.4189 - acc: 0.8588 - val_loss: 1.1532 - val_acc: 0.5100\n",
      "Epoch 8/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.4284 - acc: 0.875 - ETA: 4s - loss: 0.3726 - acc: 0.875 - ETA: 4s - loss: 0.3488 - acc: 0.895 - ETA: 4s - loss: 0.3474 - acc: 0.890 - ETA: 4s - loss: 0.3352 - acc: 0.906 - ETA: 4s - loss: 0.3371 - acc: 0.911 - ETA: 4s - loss: 0.3533 - acc: 0.897 - ETA: 3s - loss: 0.3614 - acc: 0.898 - ETA: 3s - loss: 0.3638 - acc: 0.906 - ETA: 3s - loss: 0.3688 - acc: 0.896 - ETA: 3s - loss: 0.3630 - acc: 0.897 - ETA: 3s - loss: 0.3700 - acc: 0.895 - ETA: 2s - loss: 0.3674 - acc: 0.896 - ETA: 2s - loss: 0.3722 - acc: 0.895 - ETA: 2s - loss: 0.3685 - acc: 0.897 - ETA: 2s - loss: 0.3721 - acc: 0.892 - ETA: 2s - loss: 0.3763 - acc: 0.889 - ETA: 2s - loss: 0.3766 - acc: 0.887 - ETA: 1s - loss: 0.3739 - acc: 0.886 - ETA: 1s - loss: 0.3805 - acc: 0.885 - ETA: 1s - loss: 0.3758 - acc: 0.888 - ETA: 1s - loss: 0.3702 - acc: 0.890 - ETA: 1s - loss: 0.3684 - acc: 0.891 - ETA: 0s - loss: 0.3734 - acc: 0.889 - ETA: 0s - loss: 0.3771 - acc: 0.883 - ETA: 0s - loss: 0.3755 - acc: 0.884 - ETA: 0s - loss: 0.3684 - acc: 0.888 - ETA: 0s - loss: 0.3685 - acc: 0.888 - ETA: 0s - loss: 0.3708 - acc: 0.889 - 6s 6ms/step - loss: 0.3707 - acc: 0.8888 - val_loss: 1.0743 - val_acc: 0.5800\n",
      "Epoch 9/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.2597 - acc: 0.968 - ETA: 4s - loss: 0.3601 - acc: 0.890 - ETA: 4s - loss: 0.3152 - acc: 0.916 - ETA: 4s - loss: 0.2924 - acc: 0.929 - ETA: 4s - loss: 0.3033 - acc: 0.918 - ETA: 4s - loss: 0.3172 - acc: 0.916 - ETA: 4s - loss: 0.2988 - acc: 0.924 - ETA: 3s - loss: 0.2977 - acc: 0.929 - ETA: 3s - loss: 0.3256 - acc: 0.913 - ETA: 3s - loss: 0.3291 - acc: 0.909 - ETA: 3s - loss: 0.3238 - acc: 0.911 - ETA: 3s - loss: 0.3366 - acc: 0.906 - ETA: 2s - loss: 0.3310 - acc: 0.906 - ETA: 2s - loss: 0.3326 - acc: 0.906 - ETA: 2s - loss: 0.3331 - acc: 0.902 - ETA: 2s - loss: 0.3324 - acc: 0.902 - ETA: 2s - loss: 0.3288 - acc: 0.904 - ETA: 2s - loss: 0.3341 - acc: 0.897 - ETA: 1s - loss: 0.3307 - acc: 0.896 - ETA: 1s - loss: 0.3275 - acc: 0.895 - ETA: 1s - loss: 0.3196 - acc: 0.897 - ETA: 1s - loss: 0.3203 - acc: 0.897 - ETA: 1s - loss: 0.3192 - acc: 0.898 - ETA: 0s - loss: 0.3177 - acc: 0.899 - ETA: 0s - loss: 0.3175 - acc: 0.898 - ETA: 0s - loss: 0.3151 - acc: 0.899 - ETA: 0s - loss: 0.3257 - acc: 0.892 - ETA: 0s - loss: 0.3292 - acc: 0.892 - ETA: 0s - loss: 0.3285 - acc: 0.895 - 6s 6ms/step - loss: 0.3270 - acc: 0.8963 - val_loss: 1.1159 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "935/935 [==============================] - ETA: 4s - loss: 0.3207 - acc: 0.906 - ETA: 4s - loss: 0.2815 - acc: 0.921 - ETA: 4s - loss: 0.2967 - acc: 0.895 - ETA: 4s - loss: 0.2798 - acc: 0.914 - ETA: 4s - loss: 0.2848 - acc: 0.900 - ETA: 4s - loss: 0.2911 - acc: 0.901 - ETA: 3s - loss: 0.2867 - acc: 0.897 - ETA: 3s - loss: 0.2895 - acc: 0.894 - ETA: 3s - loss: 0.2891 - acc: 0.892 - ETA: 3s - loss: 0.2707 - acc: 0.903 - ETA: 3s - loss: 0.2592 - acc: 0.911 - ETA: 3s - loss: 0.2604 - acc: 0.911 - ETA: 2s - loss: 0.2723 - acc: 0.908 - ETA: 2s - loss: 0.2659 - acc: 0.912 - ETA: 2s - loss: 0.2657 - acc: 0.916 - ETA: 2s - loss: 0.2602 - acc: 0.919 - ETA: 2s - loss: 0.2641 - acc: 0.917 - ETA: 2s - loss: 0.2661 - acc: 0.916 - ETA: 1s - loss: 0.2594 - acc: 0.921 - ETA: 1s - loss: 0.2595 - acc: 0.920 - ETA: 1s - loss: 0.2604 - acc: 0.919 - ETA: 1s - loss: 0.2631 - acc: 0.914 - ETA: 1s - loss: 0.2644 - acc: 0.914 - ETA: 0s - loss: 0.2654 - acc: 0.912 - ETA: 0s - loss: 0.2701 - acc: 0.910 - ETA: 0s - loss: 0.2730 - acc: 0.909 - ETA: 0s - loss: 0.2708 - acc: 0.912 - ETA: 0s - loss: 0.2702 - acc: 0.912 - ETA: 0s - loss: 0.2702 - acc: 0.913 - 6s 6ms/step - loss: 0.2710 - acc: 0.9123 - val_loss: 1.1183 - val_acc: 0.5800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x168f7b01cc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(hidden_size, input_shape=(timesteps, data_dim)), merge_mode='concat'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_vecs, to_categorical(y_train), epochs=num_epochs, validation_data=(val_vecs, to_categorical(y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('./model/bi_lstm_3/bi_lstm_model_01.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.54687500 0.87500000 0.67307692        40\n",
      "          1  0.50000000 0.30000000 0.37500000        20\n",
      "          2  0.70833333 0.42500000 0.53125000        40\n",
      "\n",
      "avg / total  0.60208333 0.58000000 0.55673077       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('./model/bi_lstm_3/bi_lstm_model_01.h5')\n",
    "y_pred = model.predict(val_vecs)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_validation, y_pred, labels = [0, 1, 2], digits=8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
