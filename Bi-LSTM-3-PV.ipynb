{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral\n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral\n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral\n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral\n",
       "4                minyak jarak castor oil <number> ml  neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/train.csv\")\n",
    "# clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_train_full.csv\")\n",
    "clean_train_comments['content'] = clean_train_comments['content'].apply(preprocess)\n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[gerindra, alihkan, rekomendasi, ke, agus, an,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[cuci, tangan, pakai, sunlight, stelah, itu, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[kasus, toko, obat, digerebek, fpi, propam, ak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[menkeu, melemah, nya, rupiah, lebih, berpenga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[minyak, jarak, castor, oil, number, ml]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity  \\\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral   \n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral   \n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral   \n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral   \n",
       "4                minyak jarak castor oil <number> ml  neutral   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [gerindra, alihkan, rekomendasi, ke, agus, an,...          1  \n",
       "1  [cuci, tangan, pakai, sunlight, stelah, itu, p...          1  \n",
       "2  [kasus, toko, obat, digerebek, fpi, propam, ak...          1  \n",
       "3  [menkeu, melemah, nya, rupiah, lebih, berpenga...          1  \n",
       "4           [minyak, jarak, castor, oil, number, ml]          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "clean_train_comments['content'] = clean_train_comments['content'].astype('str') \n",
    "clean_train_comments.dtypes\n",
    "clean_train_comments['tokens'] = clean_train_comments['content'].apply(tokenizer.tokenize)\n",
    "clean_train_comments['sentiment'] = clean_train_comments['polarity'].astype('category').cat.codes\n",
    "   \n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative\n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative\n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative\n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative\n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/test.csv\")\n",
    "# clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_testing_full.csv\")\n",
    "clean_test_comments['content'] = clean_test_comments['content'].apply(preprocess)\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kemarin, gue, datang, ke, tempat, makan, baru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kayak, nya, sih, gue, tidak, akan, mau, balik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kalau, dipikirpikir, sebenarnya, tidak, ada, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ini, pertama, kalinya, gua, ke, bank, buat, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[waktu, sampai, dengan, gue, pernah, disuruh, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity  \\\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative   \n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative   \n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative   \n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative   \n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [kemarin, gue, datang, ke, tempat, makan, baru...          0  \n",
       "1  [kayak, nya, sih, gue, tidak, akan, mau, balik...          0  \n",
       "2  [kalau, dipikirpikir, sebenarnya, tidak, ada, ...          0  \n",
       "3  [ini, pertama, kalinya, gua, ke, bank, buat, n...          0  \n",
       "4  [waktu, sampai, dengan, gue, pernah, disuruh, ...          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments['content'] = clean_test_comments['content'].astype('str') \n",
    "clean_test_comments.dtypes\n",
    "clean_test_comments[\"tokens\"] = clean_test_comments[\"content\"].apply(tokenizer.tokenize)\n",
    "clean_test_comments['sentiment'] = clean_test_comments['polarity'].astype('category').cat.codes\n",
    "\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = clean_train_comments['content']\n",
    "x_validation = clean_test_comments['content']\n",
    "y_train = clean_train_comments['sentiment']\n",
    "y_validation = clean_test_comments['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_text(text,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(text.index, text):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "x_train = labelize_text(x_train, 'TRAIN')\n",
    "x_validation = labelize_text(x_validation, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 85\n",
    "data_dim = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec = Word2Vec.load(\"./vectorizer/tripadvisor/word2vec_300.model\")\n",
    "word2vec = Word2Vec.load('./prosa-w2v/prosa.vec')\n",
    "tfidf = pickle.load(open('./vectorizer/tripadvisor/tfidf.pickle', 'rb'))\n",
    "model_dbow = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dbow.model\")\n",
    "model_dmc = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmc.model\")\n",
    "model_dmm = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmm.model\")\n",
    "\n",
    "def build_doc_Vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += np.append(model_dbow[word] * tfidf[word], model_dmm[word] * tfidf[word])\n",
    "            count += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "def build_Vector(tokens, word_size, doc_size):\n",
    "    doc_vec = build_doc_Vector(tokens, doc_size)\n",
    "    vec = np.zeros((MAX_SEQUENCE_LENGTH - len(tokens), doc_size + word_size))\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            word_vec = np.append(doc_vec, word2vec[word])\n",
    "            vec = np.append(vec, word_vec)\n",
    "        except KeyError: \n",
    "            word_vec = np.append(doc_vec, np.zeros((1, word_size)))\n",
    "            vec = np.append(vec, word_vec)\n",
    "            continue\n",
    "    vec.reshape(MAX_SEQUENCE_LENGTH, doc_size + word_size)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "935it [00:01, 763.65it/s] \n",
      "100it [00:00, 1046.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "val_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_validation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "hidden_size = 10\n",
    "timesteps = MAX_SEQUENCE_LENGTH\n",
    "num_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = len(train_vecs)\n",
    "num_data_val = len(val_vecs)\n",
    "\n",
    "train_vecs = train_vecs.reshape((num_data, timesteps, data_dim))\n",
    "y_train = y_train.reshape((num_data, num_class))\n",
    "val_vecs = val_vecs.reshape((num_data_val, timesteps, data_dim))\n",
    "y_validation = y_validation.reshape((num_data_val, num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 935 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "935/935 [==============================] - ETA: 1:30 - loss: 1.3174 - acc: 0.312 - ETA: 45s - loss: 1.2192 - acc: 0.359 - ETA: 30s - loss: 1.1794 - acc: 0.37 - ETA: 22s - loss: 1.1845 - acc: 0.35 - ETA: 18s - loss: 1.1753 - acc: 0.36 - ETA: 14s - loss: 1.1869 - acc: 0.34 - ETA: 12s - loss: 1.1743 - acc: 0.34 - ETA: 10s - loss: 1.1746 - acc: 0.36 - ETA: 9s - loss: 1.1560 - acc: 0.3819 - ETA: 8s - loss: 1.1507 - acc: 0.400 - ETA: 7s - loss: 1.1360 - acc: 0.400 - ETA: 6s - loss: 1.1269 - acc: 0.408 - ETA: 5s - loss: 1.1191 - acc: 0.413 - ETA: 5s - loss: 1.1210 - acc: 0.406 - ETA: 4s - loss: 1.1256 - acc: 0.400 - ETA: 4s - loss: 1.1210 - acc: 0.406 - ETA: 3s - loss: 1.1174 - acc: 0.406 - ETA: 3s - loss: 1.1064 - acc: 0.416 - ETA: 2s - loss: 1.1051 - acc: 0.414 - ETA: 2s - loss: 1.1000 - acc: 0.417 - ETA: 2s - loss: 1.0966 - acc: 0.419 - ETA: 1s - loss: 1.0946 - acc: 0.421 - ETA: 1s - loss: 1.0895 - acc: 0.425 - ETA: 1s - loss: 1.0856 - acc: 0.428 - ETA: 1s - loss: 1.0799 - acc: 0.435 - ETA: 0s - loss: 1.0790 - acc: 0.432 - ETA: 0s - loss: 1.0746 - acc: 0.437 - ETA: 0s - loss: 1.0679 - acc: 0.440 - ETA: 0s - loss: 1.0651 - acc: 0.441 - 7s 7ms/step - loss: 1.0646 - acc: 0.4417 - val_loss: 1.0293 - val_acc: 0.4900\n",
      "Epoch 2/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.8816 - acc: 0.625 - ETA: 2s - loss: 0.8711 - acc: 0.593 - ETA: 2s - loss: 0.8575 - acc: 0.614 - ETA: 2s - loss: 0.8574 - acc: 0.601 - ETA: 2s - loss: 0.8773 - acc: 0.618 - ETA: 2s - loss: 0.8745 - acc: 0.604 - ETA: 2s - loss: 0.8628 - acc: 0.611 - ETA: 2s - loss: 0.8643 - acc: 0.613 - ETA: 2s - loss: 0.8644 - acc: 0.621 - ETA: 2s - loss: 0.8614 - acc: 0.621 - ETA: 1s - loss: 0.8689 - acc: 0.613 - ETA: 1s - loss: 0.8709 - acc: 0.612 - ETA: 1s - loss: 0.8607 - acc: 0.620 - ETA: 1s - loss: 0.8541 - acc: 0.629 - ETA: 1s - loss: 0.8468 - acc: 0.637 - ETA: 1s - loss: 0.8410 - acc: 0.638 - ETA: 1s - loss: 0.8394 - acc: 0.641 - ETA: 1s - loss: 0.8348 - acc: 0.645 - ETA: 1s - loss: 0.8317 - acc: 0.646 - ETA: 1s - loss: 0.8363 - acc: 0.640 - ETA: 0s - loss: 0.8403 - acc: 0.644 - ETA: 0s - loss: 0.8370 - acc: 0.646 - ETA: 0s - loss: 0.8379 - acc: 0.646 - ETA: 0s - loss: 0.8366 - acc: 0.649 - ETA: 0s - loss: 0.8320 - acc: 0.651 - ETA: 0s - loss: 0.8357 - acc: 0.646 - ETA: 0s - loss: 0.8341 - acc: 0.653 - ETA: 0s - loss: 0.8292 - acc: 0.654 - ETA: 0s - loss: 0.8307 - acc: 0.650 - 3s 4ms/step - loss: 0.8287 - acc: 0.6524 - val_loss: 1.0209 - val_acc: 0.5200\n",
      "Epoch 3/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.6260 - acc: 0.781 - ETA: 2s - loss: 0.5714 - acc: 0.843 - ETA: 2s - loss: 0.5859 - acc: 0.843 - ETA: 2s - loss: 0.6146 - acc: 0.812 - ETA: 2s - loss: 0.6532 - acc: 0.793 - ETA: 2s - loss: 0.6767 - acc: 0.770 - ETA: 2s - loss: 0.6949 - acc: 0.754 - ETA: 2s - loss: 0.6991 - acc: 0.753 - ETA: 2s - loss: 0.7081 - acc: 0.743 - ETA: 2s - loss: 0.7130 - acc: 0.734 - ETA: 2s - loss: 0.6983 - acc: 0.747 - ETA: 1s - loss: 0.6920 - acc: 0.750 - ETA: 1s - loss: 0.6942 - acc: 0.745 - ETA: 1s - loss: 0.6856 - acc: 0.747 - ETA: 1s - loss: 0.6796 - acc: 0.752 - ETA: 1s - loss: 0.6862 - acc: 0.750 - ETA: 1s - loss: 0.6839 - acc: 0.748 - ETA: 1s - loss: 0.6845 - acc: 0.744 - ETA: 1s - loss: 0.6882 - acc: 0.740 - ETA: 1s - loss: 0.6786 - acc: 0.746 - ETA: 0s - loss: 0.6776 - acc: 0.745 - ETA: 0s - loss: 0.6844 - acc: 0.738 - ETA: 0s - loss: 0.6767 - acc: 0.743 - ETA: 0s - loss: 0.6801 - acc: 0.743 - ETA: 0s - loss: 0.6779 - acc: 0.742 - ETA: 0s - loss: 0.6761 - acc: 0.742 - ETA: 0s - loss: 0.6755 - acc: 0.741 - ETA: 0s - loss: 0.6799 - acc: 0.740 - ETA: 0s - loss: 0.6764 - acc: 0.744 - 3s 4ms/step - loss: 0.6777 - acc: 0.7455 - val_loss: 1.0000 - val_acc: 0.5700\n",
      "Epoch 4/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.5687 - acc: 0.781 - ETA: 2s - loss: 0.4912 - acc: 0.828 - ETA: 2s - loss: 0.5005 - acc: 0.812 - ETA: 2s - loss: 0.5037 - acc: 0.820 - ETA: 2s - loss: 0.5241 - acc: 0.806 - ETA: 2s - loss: 0.5493 - acc: 0.786 - ETA: 2s - loss: 0.5637 - acc: 0.781 - ETA: 2s - loss: 0.5591 - acc: 0.781 - ETA: 2s - loss: 0.5458 - acc: 0.802 - ETA: 2s - loss: 0.5511 - acc: 0.803 - ETA: 2s - loss: 0.5378 - acc: 0.809 - ETA: 1s - loss: 0.5414 - acc: 0.802 - ETA: 1s - loss: 0.5345 - acc: 0.812 - ETA: 1s - loss: 0.5366 - acc: 0.812 - ETA: 1s - loss: 0.5416 - acc: 0.808 - ETA: 1s - loss: 0.5477 - acc: 0.798 - ETA: 1s - loss: 0.5454 - acc: 0.799 - ETA: 1s - loss: 0.5494 - acc: 0.796 - ETA: 1s - loss: 0.5443 - acc: 0.801 - ETA: 1s - loss: 0.5495 - acc: 0.795 - ETA: 0s - loss: 0.5546 - acc: 0.794 - ETA: 0s - loss: 0.5544 - acc: 0.791 - ETA: 0s - loss: 0.5520 - acc: 0.792 - ETA: 0s - loss: 0.5597 - acc: 0.789 - ETA: 0s - loss: 0.5612 - acc: 0.791 - ETA: 0s - loss: 0.5598 - acc: 0.794 - ETA: 0s - loss: 0.5545 - acc: 0.796 - ETA: 0s - loss: 0.5570 - acc: 0.794 - ETA: 0s - loss: 0.5621 - acc: 0.790 - 3s 4ms/step - loss: 0.5606 - acc: 0.7914 - val_loss: 1.0497 - val_acc: 0.5200\n",
      "Epoch 5/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.4624 - acc: 0.875 - ETA: 2s - loss: 0.4234 - acc: 0.906 - ETA: 2s - loss: 0.3825 - acc: 0.937 - ETA: 2s - loss: 0.4407 - acc: 0.875 - ETA: 2s - loss: 0.4340 - acc: 0.881 - ETA: 2s - loss: 0.4207 - acc: 0.885 - ETA: 2s - loss: 0.4125 - acc: 0.879 - ETA: 2s - loss: 0.4419 - acc: 0.867 - ETA: 2s - loss: 0.4607 - acc: 0.850 - ETA: 2s - loss: 0.4612 - acc: 0.850 - ETA: 1s - loss: 0.4567 - acc: 0.855 - ETA: 1s - loss: 0.4596 - acc: 0.862 - ETA: 1s - loss: 0.4649 - acc: 0.853 - ETA: 1s - loss: 0.4722 - acc: 0.850 - ETA: 1s - loss: 0.4897 - acc: 0.841 - ETA: 1s - loss: 0.4893 - acc: 0.839 - ETA: 1s - loss: 0.4928 - acc: 0.836 - ETA: 1s - loss: 0.4835 - acc: 0.842 - ETA: 1s - loss: 0.4890 - acc: 0.840 - ETA: 1s - loss: 0.4879 - acc: 0.840 - ETA: 0s - loss: 0.4936 - acc: 0.837 - ETA: 0s - loss: 0.4904 - acc: 0.838 - ETA: 0s - loss: 0.4906 - acc: 0.835 - ETA: 0s - loss: 0.4896 - acc: 0.834 - ETA: 0s - loss: 0.4853 - acc: 0.836 - ETA: 0s - loss: 0.4806 - acc: 0.837 - ETA: 0s - loss: 0.4806 - acc: 0.838 - ETA: 0s - loss: 0.4778 - acc: 0.841 - ETA: 0s - loss: 0.4771 - acc: 0.842 - 3s 4ms/step - loss: 0.4757 - acc: 0.8439 - val_loss: 1.0051 - val_acc: 0.5900\n",
      "Epoch 6/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.5284 - acc: 0.812 - ETA: 2s - loss: 0.4510 - acc: 0.875 - ETA: 2s - loss: 0.4079 - acc: 0.895 - ETA: 2s - loss: 0.4169 - acc: 0.890 - ETA: 2s - loss: 0.4139 - acc: 0.893 - ETA: 2s - loss: 0.4032 - acc: 0.895 - ETA: 2s - loss: 0.3996 - acc: 0.883 - ETA: 2s - loss: 0.4126 - acc: 0.875 - ETA: 2s - loss: 0.4156 - acc: 0.875 - ETA: 2s - loss: 0.4251 - acc: 0.875 - ETA: 2s - loss: 0.4189 - acc: 0.872 - ETA: 1s - loss: 0.4098 - acc: 0.875 - ETA: 1s - loss: 0.3988 - acc: 0.879 - ETA: 1s - loss: 0.4026 - acc: 0.879 - ETA: 1s - loss: 0.4011 - acc: 0.877 - ETA: 1s - loss: 0.4004 - acc: 0.875 - ETA: 1s - loss: 0.3987 - acc: 0.875 - ETA: 1s - loss: 0.3971 - acc: 0.876 - ETA: 1s - loss: 0.3892 - acc: 0.881 - ETA: 1s - loss: 0.3857 - acc: 0.884 - ETA: 0s - loss: 0.3868 - acc: 0.886 - ETA: 0s - loss: 0.3910 - acc: 0.886 - ETA: 0s - loss: 0.3937 - acc: 0.883 - ETA: 0s - loss: 0.3942 - acc: 0.878 - ETA: 0s - loss: 0.3987 - acc: 0.875 - ETA: 0s - loss: 0.4034 - acc: 0.871 - ETA: 0s - loss: 0.4016 - acc: 0.871 - ETA: 0s - loss: 0.3961 - acc: 0.873 - ETA: 0s - loss: 0.3911 - acc: 0.876 - 4s 4ms/step - loss: 0.3930 - acc: 0.8749 - val_loss: 1.1243 - val_acc: 0.5500\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - ETA: 2s - loss: 0.3902 - acc: 0.812 - ETA: 2s - loss: 0.3578 - acc: 0.875 - ETA: 2s - loss: 0.3249 - acc: 0.895 - ETA: 2s - loss: 0.3223 - acc: 0.898 - ETA: 2s - loss: 0.3331 - acc: 0.893 - ETA: 2s - loss: 0.3200 - acc: 0.895 - ETA: 2s - loss: 0.3368 - acc: 0.892 - ETA: 2s - loss: 0.3461 - acc: 0.894 - ETA: 2s - loss: 0.3474 - acc: 0.892 - ETA: 2s - loss: 0.3504 - acc: 0.890 - ETA: 2s - loss: 0.3437 - acc: 0.894 - ETA: 1s - loss: 0.3474 - acc: 0.893 - ETA: 1s - loss: 0.3377 - acc: 0.899 - ETA: 1s - loss: 0.3341 - acc: 0.901 - ETA: 1s - loss: 0.3403 - acc: 0.893 - ETA: 1s - loss: 0.3358 - acc: 0.896 - ETA: 1s - loss: 0.3359 - acc: 0.895 - ETA: 1s - loss: 0.3393 - acc: 0.892 - ETA: 1s - loss: 0.3463 - acc: 0.891 - ETA: 1s - loss: 0.3437 - acc: 0.890 - ETA: 0s - loss: 0.3442 - acc: 0.886 - ETA: 0s - loss: 0.3413 - acc: 0.886 - ETA: 0s - loss: 0.3448 - acc: 0.884 - ETA: 0s - loss: 0.3435 - acc: 0.882 - ETA: 0s - loss: 0.3391 - acc: 0.887 - ETA: 0s - loss: 0.3410 - acc: 0.888 - ETA: 0s - loss: 0.3428 - acc: 0.887 - ETA: 0s - loss: 0.3442 - acc: 0.885 - ETA: 0s - loss: 0.3488 - acc: 0.884 - 3s 4ms/step - loss: 0.3490 - acc: 0.8845 - val_loss: 1.0351 - val_acc: 0.5900\n",
      "Epoch 8/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.2933 - acc: 0.906 - ETA: 2s - loss: 0.2716 - acc: 0.921 - ETA: 2s - loss: 0.2776 - acc: 0.927 - ETA: 2s - loss: 0.2497 - acc: 0.937 - ETA: 2s - loss: 0.2320 - acc: 0.943 - ETA: 2s - loss: 0.2583 - acc: 0.937 - ETA: 2s - loss: 0.2658 - acc: 0.919 - ETA: 2s - loss: 0.2780 - acc: 0.910 - ETA: 2s - loss: 0.2792 - acc: 0.906 - ETA: 2s - loss: 0.2750 - acc: 0.912 - ETA: 1s - loss: 0.2789 - acc: 0.909 - ETA: 1s - loss: 0.2830 - acc: 0.906 - ETA: 1s - loss: 0.2857 - acc: 0.911 - ETA: 1s - loss: 0.2858 - acc: 0.912 - ETA: 1s - loss: 0.2838 - acc: 0.916 - ETA: 1s - loss: 0.2875 - acc: 0.912 - ETA: 1s - loss: 0.2934 - acc: 0.909 - ETA: 1s - loss: 0.2917 - acc: 0.909 - ETA: 1s - loss: 0.2899 - acc: 0.912 - ETA: 1s - loss: 0.2924 - acc: 0.912 - ETA: 0s - loss: 0.2997 - acc: 0.909 - ETA: 0s - loss: 0.2958 - acc: 0.910 - ETA: 0s - loss: 0.2975 - acc: 0.910 - ETA: 0s - loss: 0.2944 - acc: 0.912 - ETA: 0s - loss: 0.2990 - acc: 0.910 - ETA: 0s - loss: 0.2995 - acc: 0.909 - ETA: 0s - loss: 0.3035 - acc: 0.908 - ETA: 0s - loss: 0.3038 - acc: 0.909 - ETA: 0s - loss: 0.3021 - acc: 0.909 - 3s 4ms/step - loss: 0.3033 - acc: 0.9080 - val_loss: 0.9950 - val_acc: 0.6200\n",
      "Epoch 9/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.2270 - acc: 0.937 - ETA: 2s - loss: 0.2275 - acc: 0.937 - ETA: 2s - loss: 0.2157 - acc: 0.958 - ETA: 2s - loss: 0.2444 - acc: 0.937 - ETA: 2s - loss: 0.2582 - acc: 0.912 - ETA: 2s - loss: 0.2540 - acc: 0.911 - ETA: 2s - loss: 0.2647 - acc: 0.910 - ETA: 2s - loss: 0.2888 - acc: 0.894 - ETA: 2s - loss: 0.2865 - acc: 0.895 - ETA: 2s - loss: 0.2925 - acc: 0.896 - ETA: 1s - loss: 0.2817 - acc: 0.903 - ETA: 1s - loss: 0.2795 - acc: 0.903 - ETA: 1s - loss: 0.2711 - acc: 0.908 - ETA: 1s - loss: 0.2726 - acc: 0.910 - ETA: 1s - loss: 0.2666 - acc: 0.914 - ETA: 1s - loss: 0.2761 - acc: 0.910 - ETA: 1s - loss: 0.2802 - acc: 0.909 - ETA: 1s - loss: 0.2820 - acc: 0.909 - ETA: 1s - loss: 0.2894 - acc: 0.909 - ETA: 1s - loss: 0.2887 - acc: 0.910 - ETA: 0s - loss: 0.2896 - acc: 0.907 - ETA: 0s - loss: 0.2904 - acc: 0.906 - ETA: 0s - loss: 0.2916 - acc: 0.903 - ETA: 0s - loss: 0.2892 - acc: 0.903 - ETA: 0s - loss: 0.2975 - acc: 0.901 - ETA: 0s - loss: 0.2981 - acc: 0.900 - ETA: 0s - loss: 0.2970 - acc: 0.900 - ETA: 0s - loss: 0.2949 - acc: 0.901 - ETA: 0s - loss: 0.2907 - acc: 0.904 - 3s 4ms/step - loss: 0.2903 - acc: 0.9048 - val_loss: 1.0006 - val_acc: 0.6300\n",
      "Epoch 10/10\n",
      "935/935 [==============================] - ETA: 2s - loss: 0.2690 - acc: 0.937 - ETA: 2s - loss: 0.2789 - acc: 0.921 - ETA: 2s - loss: 0.2185 - acc: 0.947 - ETA: 2s - loss: 0.2222 - acc: 0.937 - ETA: 2s - loss: 0.2107 - acc: 0.943 - ETA: 2s - loss: 0.2160 - acc: 0.932 - ETA: 2s - loss: 0.2096 - acc: 0.937 - ETA: 2s - loss: 0.2130 - acc: 0.937 - ETA: 2s - loss: 0.2050 - acc: 0.941 - ETA: 2s - loss: 0.2069 - acc: 0.940 - ETA: 1s - loss: 0.2195 - acc: 0.937 - ETA: 1s - loss: 0.2287 - acc: 0.929 - ETA: 1s - loss: 0.2385 - acc: 0.920 - ETA: 1s - loss: 0.2439 - acc: 0.921 - ETA: 1s - loss: 0.2339 - acc: 0.927 - ETA: 1s - loss: 0.2334 - acc: 0.927 - ETA: 1s - loss: 0.2276 - acc: 0.932 - ETA: 1s - loss: 0.2301 - acc: 0.934 - ETA: 1s - loss: 0.2411 - acc: 0.929 - ETA: 1s - loss: 0.2425 - acc: 0.926 - ETA: 0s - loss: 0.2409 - acc: 0.925 - ETA: 0s - loss: 0.2438 - acc: 0.924 - ETA: 0s - loss: 0.2437 - acc: 0.926 - ETA: 0s - loss: 0.2498 - acc: 0.923 - ETA: 0s - loss: 0.2495 - acc: 0.923 - ETA: 0s - loss: 0.2469 - acc: 0.925 - ETA: 0s - loss: 0.2483 - acc: 0.923 - ETA: 0s - loss: 0.2524 - acc: 0.920 - ETA: 0s - loss: 0.2592 - acc: 0.918 - 3s 4ms/step - loss: 0.2604 - acc: 0.9176 - val_loss: 1.1985 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e93f582a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(hidden_size, input_shape=(timesteps, data_dim)), merge_mode='concat'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_vecs, to_categorical(y_train), epochs=num_epochs, validation_data=(val_vecs, to_categorical(y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('./model/bi_lstm_3_pv/bi_lstm_model_01.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.56060606 0.92500000 0.69811321        40\n",
      "          1  0.53846154 0.35000000 0.42424242        20\n",
      "          2  0.76190476 0.40000000 0.52459016        40\n",
      "\n",
      "avg / total  0.63669664 0.60000000 0.57392983       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('./model/bi_lstm_3_pv/bi_lstm_model_01.h5')\n",
    "y_pred = model.predict(val_vecs)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_validation, y_pred, labels = [0, 1, 2], digits=8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
