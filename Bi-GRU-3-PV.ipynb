{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pattern-2.6-py3.6.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d+','<number>',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral\n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral\n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral\n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral\n",
       "4                minyak jarak castor oil <number> ml  neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/train.csv\")\n",
    "# clean_train_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_train_full.csv\")\n",
    "clean_train_comments['content'] = clean_train_comments['content'].apply(preprocess)\n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerindra alihkan rekomendasi ke agus an tanri ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[gerindra, alihkan, rekomendasi, ke, agus, an,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuci tangan pakai sunlight stelah itu pakai sa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[cuci, tangan, pakai, sunlight, stelah, itu, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kasus toko obat digerebek fpi propam akan peri...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[kasus, toko, obat, digerebek, fpi, propam, ak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menkeu melemah nya rupiah lebih berpengaruh pa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[menkeu, melemah, nya, rupiah, lebih, berpenga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minyak jarak castor oil &lt;number&gt; ml</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[minyak, jarak, castor, oil, number, ml]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content polarity  \\\n",
       "0  gerindra alihkan rekomendasi ke agus an tanri ...  neutral   \n",
       "1  cuci tangan pakai sunlight stelah itu pakai sa...  neutral   \n",
       "2  kasus toko obat digerebek fpi propam akan peri...  neutral   \n",
       "3  menkeu melemah nya rupiah lebih berpengaruh pa...  neutral   \n",
       "4                minyak jarak castor oil <number> ml  neutral   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [gerindra, alihkan, rekomendasi, ke, agus, an,...          1  \n",
       "1  [cuci, tangan, pakai, sunlight, stelah, itu, p...          1  \n",
       "2  [kasus, toko, obat, digerebek, fpi, propam, ak...          1  \n",
       "3  [menkeu, melemah, nya, rupiah, lebih, berpenga...          1  \n",
       "4           [minyak, jarak, castor, oil, number, ml]          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "clean_train_comments['content'] = clean_train_comments['content'].astype('str') \n",
    "clean_train_comments.dtypes\n",
    "clean_train_comments['tokens'] = clean_train_comments['content'].apply(tokenizer.tokenize)\n",
    "clean_train_comments['sentiment'] = clean_train_comments['polarity'].astype('category').cat.codes\n",
    "   \n",
    "clean_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative\n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative\n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative\n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative\n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/test.csv\")\n",
    "# clean_test_comments = pd.read_csv(\"./corpus/prosa/data_clean_punctuation/data_testing_full.csv\")\n",
    "clean_test_comments['content'] = clean_test_comments['content'].apply(preprocess)\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kemarin, gue, datang, ke, tempat, makan, baru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kayak, nya, sih, gue, tidak, akan, mau, balik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikirpikir sebenarnya tidak ada yang b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kalau, dipikirpikir, sebenarnya, tidak, ada, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ini, pertama, kalinya, gua, ke, bank, buat, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[waktu, sampai, dengan, gue, pernah, disuruh, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity  \\\n",
       "0  kemarin gue datang ke tempat makan baru yang a...  negative   \n",
       "1  kayak nya sih gue tidak akan mau balik lagi ke...  negative   \n",
       "2  kalau dipikirpikir sebenarnya tidak ada yang b...  negative   \n",
       "3  ini pertama kalinya gua ke bank buat ngurusin ...  negative   \n",
       "4  waktu sampai dengan gue pernah disuruh ibu lat...  negative   \n",
       "\n",
       "                                              tokens  sentiment  \n",
       "0  [kemarin, gue, datang, ke, tempat, makan, baru...          0  \n",
       "1  [kayak, nya, sih, gue, tidak, akan, mau, balik...          0  \n",
       "2  [kalau, dipikirpikir, sebenarnya, tidak, ada, ...          0  \n",
       "3  [ini, pertama, kalinya, gua, ke, bank, buat, n...          0  \n",
       "4  [waktu, sampai, dengan, gue, pernah, disuruh, ...          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_comments['content'] = clean_test_comments['content'].astype('str') \n",
    "clean_test_comments.dtypes\n",
    "clean_test_comments[\"tokens\"] = clean_test_comments[\"content\"].apply(tokenizer.tokenize)\n",
    "clean_test_comments['sentiment'] = clean_test_comments['polarity'].astype('category').cat.codes\n",
    "\n",
    "clean_test_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = clean_train_comments['content']\n",
    "x_validation = clean_test_comments['content']\n",
    "y_train = clean_train_comments['sentiment']\n",
    "y_validation = clean_test_comments['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_text(text,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(text.index, text):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "x_train = labelize_text(x_train, 'TRAIN')\n",
    "x_validation = labelize_text(x_validation, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 85\n",
    "data_dim = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec = Word2Vec.load(\"./vectorizer/tripadvisor/word2vec_300.model\")\n",
    "word2vec = Word2Vec.load('./prosa-w2v/prosa.vec')\n",
    "tfidf = pickle.load(open('./vectorizer/tripadvisor/tfidf.pickle', 'rb'))\n",
    "model_dbow = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dbow.model\")\n",
    "model_dmc = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmc.model\")\n",
    "model_dmm = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmm.model\")\n",
    "\n",
    "def build_doc_Vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += np.append(model_dbow[word] * tfidf[word], model_dmm[word] * tfidf[word])\n",
    "            count += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "def build_Vector(tokens, word_size, doc_size):\n",
    "    doc_vec = build_doc_Vector(tokens, doc_size)\n",
    "    vec = np.zeros((MAX_SEQUENCE_LENGTH - len(tokens), doc_size + word_size))\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            word_vec = np.append(doc_vec, word2vec[word])\n",
    "            vec = np.append(vec, word_vec)\n",
    "        except KeyError: \n",
    "            word_vec = np.append(doc_vec, np.zeros((1, word_size)))\n",
    "            vec = np.append(vec, word_vec)\n",
    "            continue\n",
    "    vec.reshape(MAX_SEQUENCE_LENGTH, doc_size + word_size)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "935it [00:02, 328.51it/s]\n",
      "100it [00:00, 402.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "val_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_validation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "hidden_size = 10\n",
    "timesteps = MAX_SEQUENCE_LENGTH\n",
    "num_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = len(train_vecs)\n",
    "num_data_val = len(val_vecs)\n",
    "\n",
    "train_vecs = train_vecs.reshape((num_data, timesteps, data_dim))\n",
    "y_train = y_train.reshape((num_data, num_class))\n",
    "val_vecs = val_vecs.reshape((num_data_val, timesteps, data_dim))\n",
    "y_validation = y_validation.reshape((num_data_val, num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 935 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "935/935 [==============================] - ETA: 1:57 - loss: 1.4761 - acc: 0.250 - ETA: 1:00 - loss: 1.2846 - acc: 0.375 - ETA: 40s - loss: 1.2496 - acc: 0.333 - ETA: 30s - loss: 1.2549 - acc: 0.32 - ETA: 24s - loss: 1.2239 - acc: 0.32 - ETA: 20s - loss: 1.1931 - acc: 0.35 - ETA: 17s - loss: 1.1959 - acc: 0.34 - ETA: 15s - loss: 1.1888 - acc: 0.34 - ETA: 13s - loss: 1.1770 - acc: 0.34 - ETA: 11s - loss: 1.1755 - acc: 0.33 - ETA: 10s - loss: 1.1706 - acc: 0.34 - ETA: 9s - loss: 1.1628 - acc: 0.3542 - ETA: 8s - loss: 1.1590 - acc: 0.367 - ETA: 7s - loss: 1.1493 - acc: 0.377 - ETA: 6s - loss: 1.1466 - acc: 0.381 - ETA: 6s - loss: 1.1403 - acc: 0.384 - ETA: 5s - loss: 1.1333 - acc: 0.393 - ETA: 4s - loss: 1.1282 - acc: 0.399 - ETA: 4s - loss: 1.1200 - acc: 0.407 - ETA: 3s - loss: 1.1253 - acc: 0.406 - ETA: 3s - loss: 1.1219 - acc: 0.407 - ETA: 2s - loss: 1.1216 - acc: 0.407 - ETA: 2s - loss: 1.1227 - acc: 0.406 - ETA: 1s - loss: 1.1180 - acc: 0.411 - ETA: 1s - loss: 1.1112 - acc: 0.416 - ETA: 1s - loss: 1.1046 - acc: 0.424 - ETA: 0s - loss: 1.0960 - acc: 0.430 - ETA: 0s - loss: 1.0910 - acc: 0.435 - ETA: 0s - loss: 1.0876 - acc: 0.438 - 11s 12ms/step - loss: 1.0878 - acc: 0.4385 - val_loss: 0.9475 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.8757 - acc: 0.625 - ETA: 5s - loss: 0.9489 - acc: 0.593 - ETA: 5s - loss: 0.9186 - acc: 0.604 - ETA: 5s - loss: 0.9099 - acc: 0.593 - ETA: 5s - loss: 0.9085 - acc: 0.581 - ETA: 4s - loss: 0.8772 - acc: 0.614 - ETA: 4s - loss: 0.8701 - acc: 0.625 - ETA: 4s - loss: 0.8965 - acc: 0.593 - ETA: 4s - loss: 0.8839 - acc: 0.604 - ETA: 3s - loss: 0.8789 - acc: 0.615 - ETA: 3s - loss: 0.8882 - acc: 0.608 - ETA: 3s - loss: 0.8856 - acc: 0.604 - ETA: 3s - loss: 0.8810 - acc: 0.603 - ETA: 3s - loss: 0.8738 - acc: 0.604 - ETA: 2s - loss: 0.8695 - acc: 0.614 - ETA: 2s - loss: 0.8635 - acc: 0.615 - ETA: 2s - loss: 0.8610 - acc: 0.615 - ETA: 2s - loss: 0.8621 - acc: 0.614 - ETA: 2s - loss: 0.8600 - acc: 0.613 - ETA: 1s - loss: 0.8640 - acc: 0.612 - ETA: 1s - loss: 0.8661 - acc: 0.610 - ETA: 1s - loss: 0.8672 - acc: 0.608 - ETA: 1s - loss: 0.8635 - acc: 0.616 - ETA: 1s - loss: 0.8608 - acc: 0.621 - ETA: 0s - loss: 0.8572 - acc: 0.627 - ETA: 0s - loss: 0.8563 - acc: 0.632 - ETA: 0s - loss: 0.8521 - acc: 0.635 - ETA: 0s - loss: 0.8499 - acc: 0.636 - ETA: 0s - loss: 0.8506 - acc: 0.632 - 7s 7ms/step - loss: 0.8496 - acc: 0.6342 - val_loss: 0.8942 - val_acc: 0.5900\n",
      "Epoch 3/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.7642 - acc: 0.718 - ETA: 5s - loss: 0.8371 - acc: 0.671 - ETA: 5s - loss: 0.8225 - acc: 0.666 - ETA: 5s - loss: 0.8105 - acc: 0.664 - ETA: 4s - loss: 0.7940 - acc: 0.668 - ETA: 4s - loss: 0.7799 - acc: 0.692 - ETA: 4s - loss: 0.7612 - acc: 0.709 - ETA: 4s - loss: 0.7456 - acc: 0.730 - ETA: 4s - loss: 0.7362 - acc: 0.739 - ETA: 3s - loss: 0.7477 - acc: 0.734 - ETA: 3s - loss: 0.7308 - acc: 0.741 - ETA: 3s - loss: 0.7243 - acc: 0.747 - ETA: 3s - loss: 0.7358 - acc: 0.740 - ETA: 3s - loss: 0.7337 - acc: 0.741 - ETA: 2s - loss: 0.7333 - acc: 0.739 - ETA: 2s - loss: 0.7340 - acc: 0.742 - ETA: 2s - loss: 0.7369 - acc: 0.731 - ETA: 2s - loss: 0.7302 - acc: 0.732 - ETA: 2s - loss: 0.7291 - acc: 0.733 - ETA: 1s - loss: 0.7317 - acc: 0.726 - ETA: 1s - loss: 0.7271 - acc: 0.727 - ETA: 1s - loss: 0.7234 - acc: 0.730 - ETA: 1s - loss: 0.7256 - acc: 0.725 - ETA: 1s - loss: 0.7257 - acc: 0.727 - ETA: 0s - loss: 0.7182 - acc: 0.732 - ETA: 0s - loss: 0.7155 - acc: 0.730 - ETA: 0s - loss: 0.7233 - acc: 0.724 - ETA: 0s - loss: 0.7223 - acc: 0.724 - ETA: 0s - loss: 0.7214 - acc: 0.724 - 7s 7ms/step - loss: 0.7214 - acc: 0.7241 - val_loss: 0.8698 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.7245 - acc: 0.781 - ETA: 5s - loss: 0.6421 - acc: 0.828 - ETA: 5s - loss: 0.6668 - acc: 0.781 - ETA: 5s - loss: 0.6606 - acc: 0.789 - ETA: 4s - loss: 0.6357 - acc: 0.800 - ETA: 4s - loss: 0.6304 - acc: 0.791 - ETA: 4s - loss: 0.6369 - acc: 0.785 - ETA: 4s - loss: 0.6439 - acc: 0.777 - ETA: 4s - loss: 0.6414 - acc: 0.777 - ETA: 3s - loss: 0.6222 - acc: 0.790 - ETA: 3s - loss: 0.6371 - acc: 0.784 - ETA: 3s - loss: 0.6383 - acc: 0.778 - ETA: 3s - loss: 0.6397 - acc: 0.778 - ETA: 3s - loss: 0.6566 - acc: 0.761 - ETA: 2s - loss: 0.6426 - acc: 0.770 - ETA: 2s - loss: 0.6426 - acc: 0.769 - ETA: 2s - loss: 0.6467 - acc: 0.768 - ETA: 2s - loss: 0.6520 - acc: 0.763 - ETA: 2s - loss: 0.6483 - acc: 0.764 - ETA: 1s - loss: 0.6512 - acc: 0.764 - ETA: 1s - loss: 0.6478 - acc: 0.764 - ETA: 1s - loss: 0.6484 - acc: 0.764 - ETA: 1s - loss: 0.6510 - acc: 0.766 - ETA: 1s - loss: 0.6559 - acc: 0.761 - ETA: 0s - loss: 0.6572 - acc: 0.760 - ETA: 0s - loss: 0.6541 - acc: 0.762 - ETA: 0s - loss: 0.6487 - acc: 0.766 - ETA: 0s - loss: 0.6458 - acc: 0.770 - ETA: 0s - loss: 0.6459 - acc: 0.770 - 7s 7ms/step - loss: 0.6480 - acc: 0.7690 - val_loss: 0.8619 - val_acc: 0.5800\n",
      "Epoch 5/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.6186 - acc: 0.781 - ETA: 5s - loss: 0.6292 - acc: 0.781 - ETA: 5s - loss: 0.6118 - acc: 0.781 - ETA: 5s - loss: 0.6141 - acc: 0.804 - ETA: 4s - loss: 0.6288 - acc: 0.793 - ETA: 4s - loss: 0.6338 - acc: 0.781 - ETA: 4s - loss: 0.6033 - acc: 0.803 - ETA: 4s - loss: 0.6150 - acc: 0.800 - ETA: 4s - loss: 0.6190 - acc: 0.791 - ETA: 3s - loss: 0.6226 - acc: 0.793 - ETA: 3s - loss: 0.6066 - acc: 0.804 - ETA: 3s - loss: 0.6147 - acc: 0.789 - ETA: 3s - loss: 0.6049 - acc: 0.795 - ETA: 3s - loss: 0.6051 - acc: 0.794 - ETA: 2s - loss: 0.6056 - acc: 0.797 - ETA: 2s - loss: 0.6049 - acc: 0.798 - ETA: 2s - loss: 0.6060 - acc: 0.799 - ETA: 2s - loss: 0.5984 - acc: 0.802 - ETA: 2s - loss: 0.5895 - acc: 0.807 - ETA: 1s - loss: 0.5830 - acc: 0.812 - ETA: 1s - loss: 0.5817 - acc: 0.812 - ETA: 1s - loss: 0.5845 - acc: 0.812 - ETA: 1s - loss: 0.5881 - acc: 0.811 - ETA: 1s - loss: 0.5956 - acc: 0.807 - ETA: 0s - loss: 0.6003 - acc: 0.802 - ETA: 0s - loss: 0.5989 - acc: 0.801 - ETA: 0s - loss: 0.5949 - acc: 0.806 - ETA: 0s - loss: 0.5916 - acc: 0.810 - ETA: 0s - loss: 0.5882 - acc: 0.811 - 7s 7ms/step - loss: 0.5863 - acc: 0.8128 - val_loss: 0.8603 - val_acc: 0.5700\n",
      "Epoch 6/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.3838 - acc: 0.937 - ETA: 5s - loss: 0.4647 - acc: 0.875 - ETA: 5s - loss: 0.4806 - acc: 0.875 - ETA: 5s - loss: 0.4678 - acc: 0.882 - ETA: 4s - loss: 0.4632 - acc: 0.893 - ETA: 4s - loss: 0.4657 - acc: 0.890 - ETA: 4s - loss: 0.4648 - acc: 0.888 - ETA: 4s - loss: 0.4769 - acc: 0.867 - ETA: 4s - loss: 0.5042 - acc: 0.850 - ETA: 3s - loss: 0.5045 - acc: 0.853 - ETA: 3s - loss: 0.4988 - acc: 0.849 - ETA: 3s - loss: 0.5056 - acc: 0.841 - ETA: 3s - loss: 0.5041 - acc: 0.841 - ETA: 3s - loss: 0.5162 - acc: 0.834 - ETA: 2s - loss: 0.5122 - acc: 0.837 - ETA: 2s - loss: 0.5159 - acc: 0.839 - ETA: 2s - loss: 0.5272 - acc: 0.834 - ETA: 2s - loss: 0.5267 - acc: 0.835 - ETA: 2s - loss: 0.5266 - acc: 0.833 - ETA: 1s - loss: 0.5254 - acc: 0.831 - ETA: 1s - loss: 0.5227 - acc: 0.830 - ETA: 1s - loss: 0.5233 - acc: 0.828 - ETA: 1s - loss: 0.5202 - acc: 0.828 - ETA: 1s - loss: 0.5214 - acc: 0.829 - ETA: 0s - loss: 0.5162 - acc: 0.832 - ETA: 0s - loss: 0.5150 - acc: 0.832 - ETA: 0s - loss: 0.5197 - acc: 0.828 - ETA: 0s - loss: 0.5175 - acc: 0.832 - ETA: 0s - loss: 0.5209 - acc: 0.830 - 6s 7ms/step - loss: 0.5222 - acc: 0.8299 - val_loss: 0.8623 - val_acc: 0.5800\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - ETA: 5s - loss: 0.5958 - acc: 0.750 - ETA: 5s - loss: 0.5869 - acc: 0.765 - ETA: 5s - loss: 0.5303 - acc: 0.802 - ETA: 5s - loss: 0.5144 - acc: 0.820 - ETA: 4s - loss: 0.4956 - acc: 0.818 - ETA: 4s - loss: 0.4802 - acc: 0.833 - ETA: 4s - loss: 0.4598 - acc: 0.852 - ETA: 4s - loss: 0.4585 - acc: 0.843 - ETA: 4s - loss: 0.4604 - acc: 0.843 - ETA: 3s - loss: 0.4531 - acc: 0.850 - ETA: 3s - loss: 0.4597 - acc: 0.849 - ETA: 3s - loss: 0.4683 - acc: 0.841 - ETA: 3s - loss: 0.4747 - acc: 0.841 - ETA: 3s - loss: 0.4864 - acc: 0.830 - ETA: 2s - loss: 0.4815 - acc: 0.833 - ETA: 2s - loss: 0.4832 - acc: 0.835 - ETA: 2s - loss: 0.4805 - acc: 0.840 - ETA: 2s - loss: 0.4809 - acc: 0.843 - ETA: 2s - loss: 0.4807 - acc: 0.842 - ETA: 1s - loss: 0.4877 - acc: 0.837 - ETA: 1s - loss: 0.4985 - acc: 0.831 - ETA: 1s - loss: 0.5013 - acc: 0.829 - ETA: 1s - loss: 0.5003 - acc: 0.834 - ETA: 1s - loss: 0.5013 - acc: 0.834 - ETA: 0s - loss: 0.4991 - acc: 0.835 - ETA: 0s - loss: 0.4968 - acc: 0.835 - ETA: 0s - loss: 0.4948 - acc: 0.835 - ETA: 0s - loss: 0.4911 - acc: 0.840 - ETA: 0s - loss: 0.4896 - acc: 0.841 - 6s 7ms/step - loss: 0.4895 - acc: 0.8417 - val_loss: 0.8633 - val_acc: 0.5700\n",
      "Epoch 8/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.3494 - acc: 0.937 - ETA: 5s - loss: 0.3682 - acc: 0.906 - ETA: 5s - loss: 0.4165 - acc: 0.875 - ETA: 5s - loss: 0.4410 - acc: 0.859 - ETA: 5s - loss: 0.4265 - acc: 0.875 - ETA: 4s - loss: 0.4432 - acc: 0.864 - ETA: 4s - loss: 0.4349 - acc: 0.879 - ETA: 4s - loss: 0.4232 - acc: 0.890 - ETA: 4s - loss: 0.4411 - acc: 0.888 - ETA: 4s - loss: 0.4466 - acc: 0.887 - ETA: 3s - loss: 0.4449 - acc: 0.880 - ETA: 3s - loss: 0.4434 - acc: 0.875 - ETA: 3s - loss: 0.4529 - acc: 0.867 - ETA: 3s - loss: 0.4467 - acc: 0.870 - ETA: 2s - loss: 0.4461 - acc: 0.868 - ETA: 2s - loss: 0.4476 - acc: 0.869 - ETA: 2s - loss: 0.4390 - acc: 0.871 - ETA: 2s - loss: 0.4406 - acc: 0.868 - ETA: 2s - loss: 0.4359 - acc: 0.870 - ETA: 1s - loss: 0.4307 - acc: 0.873 - ETA: 1s - loss: 0.4317 - acc: 0.872 - ETA: 1s - loss: 0.4299 - acc: 0.875 - ETA: 1s - loss: 0.4290 - acc: 0.875 - ETA: 1s - loss: 0.4356 - acc: 0.869 - ETA: 0s - loss: 0.4377 - acc: 0.867 - ETA: 0s - loss: 0.4343 - acc: 0.870 - ETA: 0s - loss: 0.4331 - acc: 0.871 - ETA: 0s - loss: 0.4349 - acc: 0.872 - ETA: 0s - loss: 0.4398 - acc: 0.869 - 7s 7ms/step - loss: 0.4379 - acc: 0.8706 - val_loss: 0.8507 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.3850 - acc: 0.906 - ETA: 5s - loss: 0.3796 - acc: 0.937 - ETA: 5s - loss: 0.3795 - acc: 0.906 - ETA: 5s - loss: 0.3911 - acc: 0.906 - ETA: 4s - loss: 0.3800 - acc: 0.900 - ETA: 4s - loss: 0.3628 - acc: 0.906 - ETA: 4s - loss: 0.3617 - acc: 0.915 - ETA: 4s - loss: 0.3601 - acc: 0.918 - ETA: 4s - loss: 0.3567 - acc: 0.916 - ETA: 3s - loss: 0.3636 - acc: 0.912 - ETA: 3s - loss: 0.3569 - acc: 0.914 - ETA: 3s - loss: 0.3609 - acc: 0.914 - ETA: 3s - loss: 0.3605 - acc: 0.913 - ETA: 3s - loss: 0.3543 - acc: 0.917 - ETA: 2s - loss: 0.3653 - acc: 0.908 - ETA: 2s - loss: 0.3672 - acc: 0.904 - ETA: 2s - loss: 0.3783 - acc: 0.897 - ETA: 2s - loss: 0.3769 - acc: 0.897 - ETA: 2s - loss: 0.3782 - acc: 0.896 - ETA: 1s - loss: 0.3850 - acc: 0.892 - ETA: 1s - loss: 0.3830 - acc: 0.894 - ETA: 1s - loss: 0.3902 - acc: 0.890 - ETA: 1s - loss: 0.3929 - acc: 0.888 - ETA: 1s - loss: 0.3968 - acc: 0.885 - ETA: 0s - loss: 0.3983 - acc: 0.886 - ETA: 0s - loss: 0.4003 - acc: 0.885 - ETA: 0s - loss: 0.3994 - acc: 0.885 - ETA: 0s - loss: 0.3944 - acc: 0.888 - ETA: 0s - loss: 0.3897 - acc: 0.891 - 7s 7ms/step - loss: 0.3890 - acc: 0.8909 - val_loss: 0.8516 - val_acc: 0.6100\n",
      "Epoch 10/10\n",
      "935/935 [==============================] - ETA: 5s - loss: 0.5144 - acc: 0.906 - ETA: 5s - loss: 0.4723 - acc: 0.859 - ETA: 5s - loss: 0.4647 - acc: 0.854 - ETA: 5s - loss: 0.4580 - acc: 0.867 - ETA: 4s - loss: 0.4510 - acc: 0.868 - ETA: 4s - loss: 0.4276 - acc: 0.875 - ETA: 4s - loss: 0.4085 - acc: 0.879 - ETA: 4s - loss: 0.4050 - acc: 0.882 - ETA: 4s - loss: 0.3939 - acc: 0.885 - ETA: 3s - loss: 0.3996 - acc: 0.881 - ETA: 3s - loss: 0.3975 - acc: 0.875 - ETA: 3s - loss: 0.3893 - acc: 0.880 - ETA: 3s - loss: 0.3885 - acc: 0.882 - ETA: 3s - loss: 0.3806 - acc: 0.883 - ETA: 2s - loss: 0.3828 - acc: 0.885 - ETA: 2s - loss: 0.3717 - acc: 0.888 - ETA: 2s - loss: 0.3721 - acc: 0.889 - ETA: 2s - loss: 0.3741 - acc: 0.888 - ETA: 2s - loss: 0.3697 - acc: 0.889 - ETA: 1s - loss: 0.3649 - acc: 0.890 - ETA: 1s - loss: 0.3664 - acc: 0.891 - ETA: 1s - loss: 0.3634 - acc: 0.892 - ETA: 1s - loss: 0.3617 - acc: 0.894 - ETA: 1s - loss: 0.3667 - acc: 0.894 - ETA: 0s - loss: 0.3653 - acc: 0.893 - ETA: 0s - loss: 0.3682 - acc: 0.895 - ETA: 0s - loss: 0.3661 - acc: 0.897 - ETA: 0s - loss: 0.3615 - acc: 0.898 - ETA: 0s - loss: 0.3638 - acc: 0.898 - 7s 7ms/step - loss: 0.3635 - acc: 0.8995 - val_loss: 0.8501 - val_acc: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157a2d9bda0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(hidden_size, input_shape=(timesteps, data_dim)), merge_mode='concat'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_vecs, to_categorical(y_train), epochs=num_epochs, validation_data=(val_vecs, to_categorical(y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('./model/bi_gru_3_pv/bi_gru_model_01.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.58181818 0.80000000 0.67368421        40\n",
      "          1  0.50000000 0.30000000 0.37500000        20\n",
      "          2  0.69696970 0.57500000 0.63013699        40\n",
      "\n",
      "avg / total  0.61151515 0.61000000 0.59652848       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('./model/bi_gru_3_pv/bi_gru_model_01.h5')\n",
    "y_pred = model.predict(val_vecs)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_validation, y_pred, labels = [0, 1, 2], digits=8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
