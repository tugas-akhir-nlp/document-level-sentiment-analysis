{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pattern-2.6-py3.6.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lokasi hotel tidak jauh dari komplek mall kali...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lokasi hotel tidak jauh dengan taksi ke area m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi hotel yang sangat strategis masih di ko...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lokasi hotel yang sangat strategis masih di ko...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokasi hotel yang strategis di tengah kota dan...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity\n",
       "0  lokasi hotel tidak jauh dari komplek mall kali...  negative\n",
       "1  lokasi hotel tidak jauh dengan taksi ke area m...  negative\n",
       "2  lokasi hotel yang sangat strategis masih di ko...  negative\n",
       "3  lokasi hotel yang sangat strategis masih di ko...  negative\n",
       "4  lokasi hotel yang strategis di tengah kota dan...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set = pd.read_csv('./corpus/tripadvisor/train_set.csv')\n",
    "test_set = pd.read_csv('./corpus/tripadvisor/test.csv')\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_label(polarity):\n",
    "    if polarity=='negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lokasi hotel tidak jauh dari komplek mall kali...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lokasi hotel tidak jauh dengan taksi ke area m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi hotel yang sangat strategis masih di ko...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lokasi hotel yang sangat strategis masih di ko...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokasi hotel yang strategis di tengah kota dan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  polarity  sentiment\n",
       "0  lokasi hotel tidak jauh dari komplek mall kali...  negative          0\n",
       "1  lokasi hotel tidak jauh dengan taksi ke area m...  negative          0\n",
       "2  lokasi hotel yang sangat strategis masih di ko...  negative          0\n",
       "3  lokasi hotel yang sangat strategis masih di ko...  negative          0\n",
       "4  lokasi hotel yang strategis di tengah kota dan...  negative          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set['sentiment'] = train_set['polarity'].apply(sentiment_label)\n",
    "test_set['sentiment'] = test_set['polarity'].apply(sentiment_label)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 2000\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(test_set['content'], test_set['sentiment'], test_size=.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = train_set['content']\n",
    "# x_validation = test_set['content']\n",
    "# y_train = train_set['sentiment']\n",
    "# y_validation = test_set['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def labelize_text(text,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(text.index, text):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "x_train = labelize_text(x_train, 'TRAIN')\n",
    "x_validation = labelize_text(x_validation, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 85\n",
    "data_dim = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec = Word2Vec.load(\"./vectorizer/tripadvisor/word2vec_300.model\")\n",
    "word2vec = Word2Vec.load('./prosa-w2v/prosa.vec')\n",
    "tfidf = pickle.load(open('./vectorizer/tripadvisor/tfidf.pickle', 'rb'))\n",
    "model_dbow = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dbow.model\")\n",
    "model_dmc = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmc.model\")\n",
    "model_dmm = Doc2Vec.load(\"./vectorizer/tripadvisor/model_dmm.model\")\n",
    "\n",
    "def build_doc_Vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += np.append(model_dbow[word] * tfidf[word], model_dmm[word] * tfidf[word])\n",
    "            count += 1\n",
    "        except KeyError: \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "def build_Vector(tokens, word_size, doc_size):\n",
    "    doc_vec = build_doc_Vector(tokens, doc_size)\n",
    "    vec = np.zeros((MAX_SEQUENCE_LENGTH - len(tokens), doc_size + word_size))\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            word_vec = np.append(doc_vec, word2vec[word])\n",
    "            vec = np.append(vec, word_vec)\n",
    "        except KeyError: \n",
    "            word_vec = np.append(doc_vec, np.zeros((1, word_size)))\n",
    "            vec = np.append(vec, word_vec)\n",
    "            continue\n",
    "    vec.reshape(MAX_SEQUENCE_LENGTH, doc_size + word_size)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "746it [00:03, 199.15it/s]\n",
      "83it [00:00, 209.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "val_vecs = np.concatenate([[build_Vector(z, 500, 200)] for z in tqdm(map(lambda x: x.words, x_validation))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 56\n",
    "num_epochs = 10\n",
    "hidden_size = 10\n",
    "timesteps = MAX_SEQUENCE_LENGTH\n",
    "num_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = len(train_vecs)\n",
    "num_data_val = len(val_vecs)\n",
    "\n",
    "train_vecs = train_vecs.reshape((num_data, timesteps, data_dim))\n",
    "y_train = y_train.reshape((num_data, num_class))\n",
    "val_vecs = val_vecs.reshape((num_data_val, timesteps, data_dim))\n",
    "y_validation = y_validation.reshape((num_data_val, num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 746 samples, validate on 83 samples\n",
      "Epoch 1/10\n",
      "746/746 [==============================] - ETA: 1:41 - loss: 0.7662 - acc: 0.375 - ETA: 51s - loss: 0.7362 - acc: 0.437 - ETA: 34s - loss: 0.7116 - acc: 0.50 - ETA: 25s - loss: 0.7143 - acc: 0.50 - ETA: 20s - loss: 0.7017 - acc: 0.52 - ETA: 16s - loss: 0.6966 - acc: 0.52 - ETA: 13s - loss: 0.6855 - acc: 0.54 - ETA: 11s - loss: 0.6753 - acc: 0.55 - ETA: 10s - loss: 0.6713 - acc: 0.55 - ETA: 8s - loss: 0.6641 - acc: 0.5781 - ETA: 7s - loss: 0.6529 - acc: 0.605 - ETA: 6s - loss: 0.6438 - acc: 0.617 - ETA: 5s - loss: 0.6410 - acc: 0.625 - ETA: 5s - loss: 0.6402 - acc: 0.629 - ETA: 4s - loss: 0.6318 - acc: 0.639 - ETA: 3s - loss: 0.6262 - acc: 0.644 - ETA: 3s - loss: 0.6189 - acc: 0.648 - ETA: 2s - loss: 0.6118 - acc: 0.659 - ETA: 2s - loss: 0.6090 - acc: 0.666 - ETA: 1s - loss: 0.6028 - acc: 0.675 - ETA: 1s - loss: 0.6009 - acc: 0.678 - ETA: 0s - loss: 0.5993 - acc: 0.677 - ETA: 0s - loss: 0.5952 - acc: 0.679 - 11s 14ms/step - loss: 0.5948 - acc: 0.6810 - val_loss: 0.4610 - val_acc: 0.8554\n",
      "Epoch 2/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.5313 - acc: 0.781 - ETA: 4s - loss: 0.4706 - acc: 0.828 - ETA: 4s - loss: 0.4573 - acc: 0.843 - ETA: 4s - loss: 0.4621 - acc: 0.843 - ETA: 4s - loss: 0.4472 - acc: 0.856 - ETA: 4s - loss: 0.4407 - acc: 0.859 - ETA: 3s - loss: 0.4280 - acc: 0.875 - ETA: 3s - loss: 0.4289 - acc: 0.867 - ETA: 3s - loss: 0.4234 - acc: 0.875 - ETA: 3s - loss: 0.4193 - acc: 0.875 - ETA: 2s - loss: 0.4178 - acc: 0.872 - ETA: 2s - loss: 0.4220 - acc: 0.864 - ETA: 2s - loss: 0.4161 - acc: 0.867 - ETA: 2s - loss: 0.4098 - acc: 0.875 - ETA: 1s - loss: 0.4061 - acc: 0.875 - ETA: 1s - loss: 0.4001 - acc: 0.878 - ETA: 1s - loss: 0.3997 - acc: 0.880 - ETA: 1s - loss: 0.4029 - acc: 0.878 - ETA: 1s - loss: 0.3961 - acc: 0.883 - ETA: 0s - loss: 0.3946 - acc: 0.882 - ETA: 0s - loss: 0.3901 - acc: 0.883 - ETA: 0s - loss: 0.3923 - acc: 0.880 - ETA: 0s - loss: 0.3872 - acc: 0.884 - 6s 8ms/step - loss: 0.3848 - acc: 0.8861 - val_loss: 0.3034 - val_acc: 0.9036\n",
      "Epoch 3/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.3504 - acc: 0.937 - ETA: 4s - loss: 0.3040 - acc: 0.953 - ETA: 4s - loss: 0.3280 - acc: 0.937 - ETA: 4s - loss: 0.3399 - acc: 0.906 - ETA: 4s - loss: 0.3278 - acc: 0.912 - ETA: 3s - loss: 0.3231 - acc: 0.911 - ETA: 3s - loss: 0.3132 - acc: 0.915 - ETA: 3s - loss: 0.3196 - acc: 0.906 - ETA: 3s - loss: 0.3082 - acc: 0.906 - ETA: 3s - loss: 0.2952 - acc: 0.915 - ETA: 2s - loss: 0.2911 - acc: 0.914 - ETA: 2s - loss: 0.2869 - acc: 0.919 - ETA: 2s - loss: 0.2804 - acc: 0.923 - ETA: 2s - loss: 0.2764 - acc: 0.924 - ETA: 1s - loss: 0.2768 - acc: 0.925 - ETA: 1s - loss: 0.2793 - acc: 0.921 - ETA: 1s - loss: 0.2720 - acc: 0.924 - ETA: 1s - loss: 0.2685 - acc: 0.923 - ETA: 0s - loss: 0.2664 - acc: 0.924 - ETA: 0s - loss: 0.2614 - acc: 0.928 - ETA: 0s - loss: 0.2605 - acc: 0.928 - ETA: 0s - loss: 0.2548 - acc: 0.931 - ETA: 0s - loss: 0.2534 - acc: 0.932 - 6s 8ms/step - loss: 0.2552 - acc: 0.9303 - val_loss: 0.2427 - val_acc: 0.9036\n",
      "Epoch 4/10\n",
      "746/746 [==============================] - ETA: 5s - loss: 0.1374 - acc: 1.000 - ETA: 4s - loss: 0.1887 - acc: 0.953 - ETA: 4s - loss: 0.1762 - acc: 0.968 - ETA: 4s - loss: 0.1647 - acc: 0.968 - ETA: 4s - loss: 0.1845 - acc: 0.956 - ETA: 3s - loss: 0.1744 - acc: 0.958 - ETA: 3s - loss: 0.1735 - acc: 0.959 - ETA: 3s - loss: 0.1649 - acc: 0.964 - ETA: 3s - loss: 0.1607 - acc: 0.961 - ETA: 3s - loss: 0.1644 - acc: 0.959 - ETA: 2s - loss: 0.1665 - acc: 0.960 - ETA: 2s - loss: 0.1715 - acc: 0.955 - ETA: 2s - loss: 0.1655 - acc: 0.959 - ETA: 2s - loss: 0.1628 - acc: 0.959 - ETA: 1s - loss: 0.1608 - acc: 0.958 - ETA: 1s - loss: 0.1557 - acc: 0.960 - ETA: 1s - loss: 0.1498 - acc: 0.963 - ETA: 1s - loss: 0.1463 - acc: 0.965 - ETA: 0s - loss: 0.1439 - acc: 0.965 - ETA: 0s - loss: 0.1431 - acc: 0.965 - ETA: 0s - loss: 0.1438 - acc: 0.965 - ETA: 0s - loss: 0.1423 - acc: 0.967 - ETA: 0s - loss: 0.1412 - acc: 0.967 - 6s 8ms/step - loss: 0.1445 - acc: 0.9665 - val_loss: 0.1449 - val_acc: 0.9518\n",
      "Epoch 5/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.0683 - acc: 1.000 - ETA: 4s - loss: 0.0731 - acc: 1.000 - ETA: 4s - loss: 0.0697 - acc: 1.000 - ETA: 4s - loss: 0.0843 - acc: 0.992 - ETA: 4s - loss: 0.0911 - acc: 0.987 - ETA: 3s - loss: 0.0903 - acc: 0.989 - ETA: 3s - loss: 0.0867 - acc: 0.991 - ETA: 3s - loss: 0.0887 - acc: 0.988 - ETA: 3s - loss: 0.0887 - acc: 0.989 - ETA: 3s - loss: 0.0907 - acc: 0.987 - ETA: 2s - loss: 0.0935 - acc: 0.985 - ETA: 2s - loss: 0.0906 - acc: 0.987 - ETA: 2s - loss: 0.0908 - acc: 0.985 - ETA: 2s - loss: 0.0875 - acc: 0.986 - ETA: 1s - loss: 0.0843 - acc: 0.987 - ETA: 1s - loss: 0.0828 - acc: 0.988 - ETA: 1s - loss: 0.0824 - acc: 0.989 - ETA: 1s - loss: 0.0857 - acc: 0.986 - ETA: 0s - loss: 0.0848 - acc: 0.986 - ETA: 0s - loss: 0.0858 - acc: 0.987 - ETA: 0s - loss: 0.0881 - acc: 0.985 - ETA: 0s - loss: 0.0863 - acc: 0.985 - ETA: 0s - loss: 0.0859 - acc: 0.986 - 6s 8ms/step - loss: 0.0851 - acc: 0.9866 - val_loss: 0.1181 - val_acc: 0.9639\n",
      "Epoch 6/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.0463 - acc: 1.000 - ETA: 4s - loss: 0.0760 - acc: 0.984 - ETA: 4s - loss: 0.0682 - acc: 0.989 - ETA: 4s - loss: 0.0756 - acc: 0.984 - ETA: 4s - loss: 0.0721 - acc: 0.987 - ETA: 4s - loss: 0.0686 - acc: 0.989 - ETA: 3s - loss: 0.0659 - acc: 0.991 - ETA: 3s - loss: 0.0658 - acc: 0.992 - ETA: 3s - loss: 0.0622 - acc: 0.993 - ETA: 3s - loss: 0.0663 - acc: 0.990 - ETA: 2s - loss: 0.0656 - acc: 0.991 - ETA: 2s - loss: 0.0640 - acc: 0.992 - ETA: 2s - loss: 0.0635 - acc: 0.992 - ETA: 2s - loss: 0.0610 - acc: 0.993 - ETA: 1s - loss: 0.0625 - acc: 0.991 - ETA: 1s - loss: 0.0614 - acc: 0.992 - ETA: 1s - loss: 0.0606 - acc: 0.992 - ETA: 1s - loss: 0.0596 - acc: 0.993 - ETA: 0s - loss: 0.0601 - acc: 0.993 - ETA: 0s - loss: 0.0588 - acc: 0.993 - ETA: 0s - loss: 0.0580 - acc: 0.994 - ETA: 0s - loss: 0.0599 - acc: 0.992 - ETA: 0s - loss: 0.0595 - acc: 0.993 - 6s 8ms/step - loss: 0.0592 - acc: 0.9933 - val_loss: 0.1069 - val_acc: 0.9639\n",
      "Epoch 7/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.0359 - acc: 1.000 - ETA: 4s - loss: 0.0386 - acc: 1.000 - ETA: 4s - loss: 0.0392 - acc: 1.000 - ETA: 4s - loss: 0.0493 - acc: 0.992 - ETA: 3s - loss: 0.0430 - acc: 0.993 - ETA: 3s - loss: 0.0422 - acc: 0.994 - ETA: 3s - loss: 0.0400 - acc: 0.995 - ETA: 3s - loss: 0.0423 - acc: 0.992 - ETA: 2s - loss: 0.0433 - acc: 0.989 - ETA: 2s - loss: 0.0423 - acc: 0.990 - ETA: 2s - loss: 0.0418 - acc: 0.991 - ETA: 2s - loss: 0.0457 - acc: 0.989 - ETA: 2s - loss: 0.0463 - acc: 0.988 - ETA: 1s - loss: 0.0448 - acc: 0.988 - ETA: 1s - loss: 0.0447 - acc: 0.989 - ETA: 1s - loss: 0.0442 - acc: 0.990 - ETA: 1s - loss: 0.0450 - acc: 0.990 - ETA: 1s - loss: 0.0455 - acc: 0.991 - ETA: 0s - loss: 0.0447 - acc: 0.991 - ETA: 0s - loss: 0.0443 - acc: 0.992 - ETA: 0s - loss: 0.0435 - acc: 0.992 - ETA: 0s - loss: 0.0426 - acc: 0.992 - ETA: 0s - loss: 0.0416 - acc: 0.993 - 6s 7ms/step - loss: 0.0413 - acc: 0.9933 - val_loss: 0.1063 - val_acc: 0.9639\n",
      "Epoch 8/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.0583 - acc: 1.000 - ETA: 4s - loss: 0.0415 - acc: 1.000 - ETA: 4s - loss: 0.0325 - acc: 1.000 - ETA: 4s - loss: 0.0321 - acc: 1.000 - ETA: 4s - loss: 0.0319 - acc: 1.000 - ETA: 3s - loss: 0.0327 - acc: 1.000 - ETA: 3s - loss: 0.0347 - acc: 1.000 - ETA: 3s - loss: 0.0328 - acc: 1.000 - ETA: 3s - loss: 0.0342 - acc: 1.000 - ETA: 2s - loss: 0.0327 - acc: 1.000 - ETA: 2s - loss: 0.0326 - acc: 1.000 - ETA: 2s - loss: 0.0317 - acc: 1.000 - ETA: 2s - loss: 0.0312 - acc: 1.000 - ETA: 2s - loss: 0.0302 - acc: 1.000 - ETA: 1s - loss: 0.0299 - acc: 1.000 - ETA: 1s - loss: 0.0294 - acc: 1.000 - ETA: 1s - loss: 0.0296 - acc: 1.000 - ETA: 1s - loss: 0.0307 - acc: 1.000 - ETA: 0s - loss: 0.0302 - acc: 1.000 - ETA: 0s - loss: 0.0297 - acc: 1.000 - ETA: 0s - loss: 0.0298 - acc: 1.000 - ETA: 0s - loss: 0.0299 - acc: 1.000 - ETA: 0s - loss: 0.0299 - acc: 1.000 - 6s 8ms/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9639\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - ETA: 4s - loss: 0.0296 - acc: 1.000 - ETA: 4s - loss: 0.0277 - acc: 1.000 - ETA: 4s - loss: 0.0308 - acc: 1.000 - ETA: 4s - loss: 0.0286 - acc: 1.000 - ETA: 4s - loss: 0.0268 - acc: 1.000 - ETA: 3s - loss: 0.0301 - acc: 1.000 - ETA: 3s - loss: 0.0281 - acc: 1.000 - ETA: 3s - loss: 0.0280 - acc: 1.000 - ETA: 3s - loss: 0.0280 - acc: 1.000 - ETA: 3s - loss: 0.0284 - acc: 1.000 - ETA: 2s - loss: 0.0351 - acc: 0.994 - ETA: 2s - loss: 0.0340 - acc: 0.994 - ETA: 2s - loss: 0.0335 - acc: 0.995 - ETA: 2s - loss: 0.0342 - acc: 0.995 - ETA: 1s - loss: 0.0337 - acc: 0.995 - ETA: 1s - loss: 0.0326 - acc: 0.996 - ETA: 1s - loss: 0.0314 - acc: 0.996 - ETA: 1s - loss: 0.0316 - acc: 0.996 - ETA: 0s - loss: 0.0317 - acc: 0.996 - ETA: 0s - loss: 0.0311 - acc: 0.996 - ETA: 0s - loss: 0.0302 - acc: 0.997 - ETA: 0s - loss: 0.0313 - acc: 0.995 - ETA: 0s - loss: 0.0314 - acc: 0.995 - 6s 8ms/step - loss: 0.0311 - acc: 0.9960 - val_loss: 0.1014 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "746/746 [==============================] - ETA: 4s - loss: 0.0288 - acc: 1.000 - ETA: 4s - loss: 0.0362 - acc: 1.000 - ETA: 4s - loss: 0.0370 - acc: 0.989 - ETA: 4s - loss: 0.0379 - acc: 0.984 - ETA: 4s - loss: 0.0385 - acc: 0.987 - ETA: 4s - loss: 0.0345 - acc: 0.989 - ETA: 3s - loss: 0.0319 - acc: 0.991 - ETA: 3s - loss: 0.0294 - acc: 0.992 - ETA: 3s - loss: 0.0281 - acc: 0.993 - ETA: 3s - loss: 0.0270 - acc: 0.993 - ETA: 2s - loss: 0.0267 - acc: 0.994 - ETA: 2s - loss: 0.0261 - acc: 0.994 - ETA: 2s - loss: 0.0265 - acc: 0.995 - ETA: 2s - loss: 0.0263 - acc: 0.995 - ETA: 1s - loss: 0.0256 - acc: 0.995 - ETA: 1s - loss: 0.0247 - acc: 0.996 - ETA: 1s - loss: 0.0240 - acc: 0.996 - ETA: 1s - loss: 0.0253 - acc: 0.996 - ETA: 1s - loss: 0.0257 - acc: 0.996 - ETA: 0s - loss: 0.0252 - acc: 0.996 - ETA: 0s - loss: 0.0253 - acc: 0.997 - ETA: 0s - loss: 0.0249 - acc: 0.997 - ETA: 0s - loss: 0.0251 - acc: 0.997 - 6s 8ms/step - loss: 0.0251 - acc: 0.9973 - val_loss: 0.0949 - val_acc: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19bad49d6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(hidden_size, input_shape=(timesteps, data_dim)), merge_mode='concat'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_vecs, y_train, epochs=num_epochs, validation_data=[val_vecs, y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('./model/bi_lstm_pv/bi_lstm_model_01.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9759036144578314\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.96491228 1.00000000 0.98214286        55\n",
      "          1  1.00000000 0.92857143 0.96296296        28\n",
      "\n",
      "avg / total  0.97674910 0.97590361 0.97567253        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('./model/bi_lstm_pv/bi_lstm_model_01.h5')\n",
    "y_pred = model.predict(val_vecs)\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i][0] = round(y_pred[i][0])\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, labels = [0, 1], digits=8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
